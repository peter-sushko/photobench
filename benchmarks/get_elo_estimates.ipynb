{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Elo Ratings:\n",
      "cosine: 1212.04\n",
      "aurora: 1020.17\n",
      "hive: 1006.01\n",
      "ip2p: 1004.19\n",
      "mb: 961.23\n",
      "null_text: 926.55\n",
      "sdedit: 869.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "data = pd.read_csv('pairwise_results.csv')\n",
    "data = data[~data['Model A'].str.contains('ssim') & ~data['Model B'].str.contains('ssim')]\n",
    "\n",
    "# Extract unique models and map to indices\n",
    "unique_models = set(data['Model A']).union(set(data['Model B']))\n",
    "model_list = list(unique_models)\n",
    "model_index = {model: idx for idx, model in enumerate(model_list)}\n",
    "num_models = len(model_list)\n",
    "\n",
    "# Initialize ratings to 1000\n",
    "initial_ratings = np.ones(num_models) * 1000\n",
    "\n",
    "# Function to compute negative log-likelihood\n",
    "def neg_log_likelihood(ratings):\n",
    "    LL = 0.0\n",
    "    for idx, row in data.iterrows():\n",
    "        model_a = row['Model A']\n",
    "        model_b = row['Model B']\n",
    "        a_idx = model_index[model_a]\n",
    "        b_idx = model_index[model_b]\n",
    "        Ra = ratings[a_idx]\n",
    "        Rb = ratings[b_idx]\n",
    "        A_wins = row['Model A Wins']\n",
    "        B_wins = row['Model B Wins']\n",
    "        Ties = row['Ties']\n",
    "        N = A_wins + B_wins + Ties\n",
    "        # Expected score for model A\n",
    "        Ea = 1 / (1 + 10 ** ((Rb - Ra) / 400))\n",
    "        # Total observed score for model A\n",
    "        Sa = A_wins + 0.5 * Ties\n",
    "        Sb = B_wins + 0.5 * Ties  # Sa + Sb = N\n",
    "        # Avoid log(0) by adding a small epsilon\n",
    "        epsilon = 1e-10\n",
    "        Ea = min(max(Ea, epsilon), 1 - epsilon)\n",
    "        # Accumulate negative log-likelihood\n",
    "        LL -= Sa * np.log(Ea) + Sb * np.log(1 - Ea)\n",
    "    return LL\n",
    "\n",
    "# Constraint: Mean rating is 1000\n",
    "def mean_rating_constraint(ratings):\n",
    "    return np.mean(ratings) - 1000\n",
    "\n",
    "# Optimization\n",
    "constraints = {'type': 'eq', 'fun': mean_rating_constraint}\n",
    "result = minimize(neg_log_likelihood, initial_ratings, method='SLSQP', constraints=constraints)\n",
    "\n",
    "# Check if optimization was successful\n",
    "if not result.success:\n",
    "    print(\"Optimization failed:\", result.message)\n",
    "\n",
    "# Get the optimized ratings\n",
    "optimized_ratings = result.x\n",
    "\n",
    "# Map ratings back to model names\n",
    "ratings = {model: optimized_ratings[model_index[model]] for model in model_list}\n",
    "\n",
    "# Sort and print the ratings\n",
    "print(\"Estimated Elo Ratings:\")\n",
    "for model_name, rating in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{model_name}: {rating:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jup-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
